# mtop

![CI](https://github.com/jeremyeder/mtop/workflows/CI/badge.svg)
![Tests](https://img.shields.io/badge/tests-53%20passing-green.svg)
![Coverage](https://img.shields.io/badge/coverage-comprehensive-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![Quality](https://img.shields.io/badge/code%20quality-production%20ready-green.svg)

`mtop` (Model Top) is a mock CLI tool for debugging and simulating `LLMInferenceService` CRDs in a Kubernetes-like environment — without requiring a live cluster. It's designed for SREs, ML engineers, and platform teams to simulate rollouts, test failure modes, and inspect the status of LLM-serving infrastructure offline.

> **Note**: This project was initially generated by ChatGPT but completely rewritten by Claude due to severe structural issues in the original code.

## 🤝 Collaboration

This project uses a collaborative development approach between Jeremy and Claude through GitHub issues. See [COLLABORATION.md](./COLLABORATION.md) for our workflow documentation.

**Current Focus**: Building GPU Heartbeat & SLO Convergence demo system with 45 tracked issues across 4 development phases.

---

## 🚀 Features

- ✅ Offline simulation of up to 100 `LLMInferenceService` CRs
- ✅ Mock support for `LLMInferenceServiceConfig`
- ✅ Full CRUD support on mocked CRs
- ✅ Realistic rollout playback (`play rollout`)
- ✅ Live-style watch command (`watch`) to track CR status changes
- ✅ Log simulation for individual model services
- ✅ Configurable via file structure (`./mocks/`)
- ✅ **mtop**: Real-time LLM inference monitoring (like `htop` for LLMs)

---

## 📦 Structure

```
mtop/
├── mtop                       # Python CLI entry point
├── mocks/
│   ├── crs/                   # LLMInferenceService CRs (20 included)
│   ├── config/                # Global LLMInferenceServiceConfig mock
│   ├── pod_logs/              # Simulated logs for LLMs
│   └── topologies/            # Rollout scenarios
```

---

## 🛠 Usage

```bash
chmod +x mtop
./mtop list                         # List all mocked LLMInferenceServices
./mtop check llm-005                # Inspect a specific CR
./mtop logs llm-005                 # View logs for a model
./mtop config                       # Show global LLM config
./mtop delete llm-005               # Delete a mock CR
./mtop create file.json             # Create CR from file
./mtop simulate canary              # Simulate canary rollout
./mtop                              # Real-time LLM inference monitoring
```

---

## 🔥 mtop: Real-time LLM Monitoring

`mtop` provides real-time monitoring of LLM inference services, similar to `htop` but specifically designed for LLM workloads.

### Features
- **Real-time metrics**: QPS, CPU usage, error rates, latency
- **Multi-model monitoring**: Track multiple LLM services simultaneously  
- **Dual-mode operation**: Works with both mock data and live clusters
- **Interactive display**: Live-updating terminal interface
- **Cluster overview**: Aggregate statistics and health indicators

### Usage

```bash
# Monitor using mock data (default)
./mtop

# Monitor live cluster
./mtop --mode live

# Monitor specific namespace
./mtop --namespace production

# Custom refresh rate
./mtop --interval 1.0

# Direct execution
./mtop                        # Real-time monitoring
```

### Display

```
🚀 mtop - LLM Inference Monitor
Mode: mock | Namespace: default | Runtime: 45s | Sort: qps
Total QPS: 12,847 • Models: 34/34 healthy • Replicas: 127
Avg CPU: 52.3% • Avg Errors: 0.8%
Controls: Ctrl+C to quit | Sort by: qps

┌─── 🔥 Live LLM Inference Traffic ───┐
│ Model                  Status    QPS   CPU   Errors  Latency  Replicas │
│ llama-3-70b-instruct   🟢 Ready   2,847  45%   0.2%    127ms    8       │
│ gpt-4-turbo           🟢 Ready   2,234  62%   0.1%    98ms     6       │
│ claude-3-opus         🟢 Ready   1,923  58%   0.3%    145ms    5       │
│ mixtral-8x7b-instruct 🟢 Ready   1,445  71%   0.5%    156ms    4       │
│ ...                                                                    │
└────────────────────────────────────────────────────────────────────────┘
```

### Requirements

mtop requires the `rich` library for terminal display:

```bash
pip install rich
```

---

## 🎬 Rollout Simulation

```bash
./mtop simulate canary
./mtop simulate bluegreen
./mtop simulate rolling
./mtop simulate shadow
```

Watch rollouts with animation:

```bash
./watch_rollout.py --topology rolling --autoplay --delay 2
```

---

## 🌐 Live Cluster Support

`mtop` can operate in **live mode** using actual Kubernetes resources.

### 🔁 Modes

| Mode   | Description                       |
|--------|-----------------------------------|
| `mock` | Use local files in `./mocks/`     |
| `live` | Use kubernetes API to talk to a live cluster|

### 🔧 Set the Mode

Via environment variable:

```bash
export LLD_MODE=live
./mtop list
```

Or per-command:

```bash
./mtop --mode live list
./mtop --mode mock list
```

---

## 🧪 Development & Testing

**Requires: Python 3.11+**

The tool will check your Python version on startup and exit with an error if you're running an older version.

### Code Quality Features
- ✅ **Comprehensive Testing**: 53 tests including unit and integration tests
- ✅ **Type Hints**: Full type annotations for better IDE support
- ✅ **Security Scanning**: Automated vulnerability scanning with safety and bandit
- ✅ **Code Quality Gates**: Coverage thresholds and complexity checks
- ✅ **Dependency Management**: Automated updates with Dependabot
- ✅ **Error Handling**: Graceful error handling for all operations

### Running Tests
```bash
# Install test dependencies
pip install -r requirements.txt

# Run all tests
python3 -m pytest tests/ -v

# Run with coverage
python3 -m pytest tests/ --cov=. --cov-report=term
```

### Dependencies
See `requirements.txt` for pinned dependency versions with security scanning.

---

## Installation

### 1. Install Python dependencies

**Requirements: Python 3.11 or later**

```bash
# Check your Python version
python3 --version

# Install dependencies
pip install -r requirements.txt
```

### 2. Make executable

```bash
chmod +x mtop
```

### 3. Test installation

```bash
./mtop help
./mtop list
```

---

## 📜 License

MIT

---

## 🤝 Contributing

Pull requests welcome for:
- Additional rollout topologies
- New simulation features
- Improved error handling
- Enhanced testing