{"version": 2, "width": 80, "height": 24, "timestamp": 1751603234, "env": {"SHELL": "/opt/homebrew/bin/bash", "TERM": "xterm-256color"}, "title": "kubectl-ld Full Demo"}
[0.012417, "o", "🎬 Starting kubectl-ld full demo (comprehensive showcase)...\r\n"]
[0.012923, "o", "🤖 Running in headless mode with automatic progression\r\n🔧 Activating virtual environment...\r\n"]
[0.015709, "o", "\r\n👋 Welcome to kubectl-ld — your LLM debugging Swiss Army knife.\r\n"]
[0.015757, "o", "⏳ Continuing in 3 seconds...\r\n"]
[3.023066, "o", "\r\n═══════════════════════════════════════════════════════════════\r\n🔸 Step 1: List supported rollout topologies\r\n"]
[3.023101, "o", "═══════════════════════════════════════════════════════════════\r\n"]
[3.083401, "o", "\u001b[36m🔧 Mode: mock\u001b[0m\r\n"]
[3.083503, "o", "📦 Available rollout topologies:\r\n"]
[3.083641, "o", "  - bluegreen\r\n  - canary\r\n  - rolling\r\n  - shadow\r\n"]
[3.090014, "o", "⏳ Continuing in 3 seconds...\r\n"]
[6.097835, "o", "\r\n═══════════════════════════════════════════════════════════════\r\n"]
[6.097982, "o", "🔸 Step 2: Simulate a 'bluegreen' rollout (realistic model upgrade)\r\n═══════════════════════════════════════════════════════════════\r\n"]
[6.157504, "o", "\u001b[36m🔧 Mode: mock\u001b[0m\r\n"]
[6.157728, "o", "\u001b[34m📡 Simulating rollout for 'bluegreen' with 2 steps...\u001b[0m\r\n"]
[6.157795, "o", "Step 1 @ 00:00:\r\n  - gpt2                      Ready        100%\r\n"]
[6.157804, "o", "  - bert-base                 Pending        0%\r\n"]
[6.15785, "o", "Step 2 @ 00:10:\r\n  - gpt2                      Terminated     0%\r\n  - bert-base                 Ready        100%\r\n"]
[6.157862, "o", "\u001b[32m✅ Simulation complete.\u001b[0m\r\n"]
[6.164434, "o", "⏳ Continuing in 3 seconds...\r\n"]
[9.16967, "o", "\r\n═══════════════════════════════════════════════════════════════\r\n🔸 Step 3: Playback that rollout visually\r\n"]
[9.169995, "o", "═══════════════════════════════════════════════════════════════\r\n"]
[9.259303, "o", "\u001b[2J\u001b[H"]
[9.261366, "o", "\u001b[92m───────────────────── \u001b[0m🔁 Rollout: Bluegreen \u001b[1m(\u001b[0mStep \u001b[1;36m1\u001b[0m/\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m   \u001b[92m ──────────────────────\u001b[0m\r\n"]
[9.262209, "o", "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\r\n┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m  Status  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraffic %\u001b[0m\u001b[1;35m \u001b[0m┃\r\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩\r\n│ gpt2                           │  🟢 Ready  │   100%    │\r\n│ bert-base                      │ 🟡 Pending │    0%     │\r\n└────────────────────────────────┴────────────┴───────────┘\r\n"]
[11.268166, "o", "\u001b[2J\u001b[H"]
[11.269418, "o", "\u001b[92m───────────────────── \u001b[0m🔁 Rollout: Bluegreen \u001b[1m(\u001b[0mStep \u001b[1;36m2\u001b[0m/\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m   \u001b[92m ──────────────────────\u001b[0m\r\n"]
[11.271328, "o", "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\r\n┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m   Status    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraffic %\u001b[0m\u001b[1;35m \u001b[0m┃\r\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\r\n│ gpt2                           │ ❌ Terminated │    0%     │\r\n│ bert-base                      │   🟢 Ready    │   100%    │\r\n└────────────────────────────────┴───────────────┴───────────┘\r\n"]
[13.284895, "o", "⏳ Continuing in 3 seconds...\r\n"]
[16.292769, "o", "\r\n═══════════════════════════════════════════════════════════════\r\n"]
[16.292867, "o", "🔸 Step 4: Check detailed status of a mock service\r\n═══════════════════════════════════════════════════════════════\r\n"]
[16.34972, "o", "\u001b[36m🔧 Mode: mock\u001b[0m\r\n"]
[16.34982, "o", "🔍 gpt2 status:\r\n - [Ready] Status: True - All systems go\r\n - [PredictorReady] Status: True - Predictor loaded\r\n"]
[16.355979, "o", "⏳ Continuing in 3 seconds...\r\n"]
[19.364208, "o", "\r\n═══════════════════════════════════════════════════════════════\r\n"]
[19.364396, "o", "🔸 Step 5: Show a real CR (gpt2) in YAML format\r\n═══════════════════════════════════════════════════════════════\r\n"]
[19.423301, "o", "\u001b[36m🔧 Mode: mock\u001b[0m\r\n"]
[19.423973, "o", "metadata:\r\n  name: gpt2\r\n  namespace: default\r\nspec:\r\n  predictor:\r\n    model:\r\n      modelName: model-2\r\n      runtime: triton\r\n      storageUri: s3://models/model-2\r\nstatus:\r\n  conditions:\r\n  - type: Ready\r\n    status: 'True'\r\n    message: All systems go\r\n  - type: PredictorReady\r\n    status: 'True'\r\n    message: Predictor loaded\r\n\r\n"]
[19.429295, "o", "⏳ Continuing in 3 seconds...\r\n"]
[22.437509, "o", "\r\n"]
[22.437647, "o", "═══════════════════════════════════════════════════════════════\r\n🔸 Step 6: View all models with status summary\r\n═══════════════════════════════════════════════════════════════\r\n"]
[22.498904, "o", "\u001b[36m🔧 Mode: mock\u001b[0m\r\n"]
[22.499358, "o", "EleutherAI/gpt-neo-1.3B             | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499438, "o", "Qwen/Qwen1.5-0.5B                   | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499479, "o", "TinyLlama/TinyLlama-1.1B-Chat-v1.0  | Ready: \u001b[31mFalse\u001b[0m\r\n"]
[22.499516, "o", "albert-base-v2                      | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499595, "o", "bert-base-uncased                   | Ready: \u001b[32mTrue\u001b[0m\r\ndeepset/roberta-base-squad2         | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499643, "o", "distilbert-base-uncased             | Ready: \u001b[31mFalse\u001b[0m\r\n"]
[22.499688, "o", "facebook/bart-large                 | Ready: \u001b[31mFalse\u001b[0m\r\n"]
[22.499706, "o", "facebook/mbart-large-50             | Ready: \u001b[31mFalse\u001b[0m\r\n"]
[22.499764, "o", "google/electra-base-discriminator   | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499772, "o", "gpt2                                | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499815, "o", "microsoft/DialoGPT-medium           | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.49985, "o", "microsoft/codebert-base             | Ready: \u001b[31mFalse\u001b[0m\r\n"]
[22.499889, "o", "openai/whisper-base                 | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499934, "o", "roberta-base                        | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.499968, "o", "sentence-transformers/all-MiniLM-L6-v2 | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.500003, "o", "stabilityai/stablelm-3b-4e1t        | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.500039, "o", "t5-base                             | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.500081, "o", "test-model                          | Ready: \u001b[31mUnknown\u001b[0m\r\n"]
[22.50012, "o", "xlnet-base-cased                    | Ready: \u001b[32mTrue\u001b[0m\r\n"]
[22.506871, "o", "⏳ Continuing in 3 seconds...\r\n"]
[25.515255, "o", "\r\n"]
[25.515436, "o", "═══════════════════════════════════════════════════════════════\r\n✅ Demo complete. kubectl-ld is your LLM debug toolkit!\r\n═══════════════════════════════════════════════════════════════\r\n"]
